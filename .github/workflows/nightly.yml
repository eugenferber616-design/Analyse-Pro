name: Nightly Data Pull & Cache (No LLM)

on:
  schedule:
    - cron: "30 0 * * *"   # täglich 00:30 UTC
  workflow_dispatch:

permissions:
  contents: write

jobs:
  run-pipeline:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # ---- Cache-DB initialisieren
      - name: Init cache DB
        run: |
          mkdir -p data/cache data/earnings data/macro/fred data/processed data/reports docs watchlists
          python - << 'PY'
          import os, sqlite3
          db_path = os.path.join('data','cache','cache.db')
          os.makedirs(os.path.dirname(db_path), exist_ok=True)
          con = sqlite3.connect(db_path)
          cur = con.cursor()
          cur.execute("""
          CREATE TABLE IF NOT EXISTS kv (
            k  TEXT PRIMARY KEY,
            v  TEXT NOT NULL,
            ts INTEGER DEFAULT (strftime('%s','now'))
          )
          """)
          cur.execute("CREATE INDEX IF NOT EXISTS ix_kv_ts ON kv(ts)")
          con.commit(); con.close()
          print("cache DB ready at", db_path)
          PY

      # ---- Secrets & Watchlists prüfen / anlegen
      - name: Prepare env and watchlists
        id: prep
        shell: bash
        env:
          FINNHUB_TOKEN:   ${{ secrets.FINNHUB_TOKEN }}
          FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
        run: |
          set -e
          TOKEN="${FINNHUB_TOKEN:-$FINNHUB_API_KEY}"
          if [ -z "$TOKEN" ]; then
            echo "❌ Kein FINNHUB_TOKEN/FINNHUB_API_KEY gesetzt (Repository Secrets)."
            exit 1
          fi
          echo "token_present=true" >> "$GITHUB_OUTPUT"

          # Aktien-Watchlist
          WL=""
          if   [ -f watchlists/mylist.txt ]; then WL="watchlists/mylist.txt"
          elif [ -f watchlists/mylist.csv ]; then WL="watchlists/mylist.csv"
          else
            echo "⚠️  Keine watchlists/mylist.* gefunden. Lege Fallback an."
            printf "symbol\nAAPL\nMSFT\nNVDA\nSPY\n" > watchlists/mylist.csv
            WL="watchlists/mylist.csv"
          fi
          echo "watchlist=$WL" >> "$GITHUB_OUTPUT"
          echo "== Aktien Watchlist =="
          head -n 5 "$WL" || true

          # ETF-Sample
          if [ ! -f watchlists/etf_sample.txt ]; then
            printf "SPY\nQQQ\nIWM\nGLD\nHYG\nXLF\nXLK\nXLE\n" > watchlists/etf_sample.txt
          fi
          echo "== ETF Sample =="
          head -n 8 watchlists/etf_sample.txt || true

          # FX-Sample (beliebige Formate, normalisieren wir im Script)
          if [ ! -f watchlists/fx_sample.txt ]; then
            printf "EURUSD\nUSD/JPY\nGBP_USD\nOANDA:AUD_USD\n" > watchlists/fx_sample.txt
          fi
          echo "== FX Sample =="
          head -n 8 watchlists/fx_sample.txt || true

      # ---- (Optional) Earnings-Kalender
      - name: Pull earnings CALENDAR (optional)
        env:
          FINNHUB_TOKEN:   ${{ secrets.FINNHUB_TOKEN || secrets.FINNHUB_API_KEY }}
          FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
        run: |
          mkdir -p data/earnings docs
          WL="${{ steps.prep.outputs.watchlist }}"
          echo "Nutze Watchlist (Kalender): $WL"
          python scripts/fetch_earnings.py --watchlist "$WL" --window-days 365
          ls -lah docs || true
          test -f docs/earnings_next.json && head -n 50 docs/earnings_next.json || true

      # ==== Earnings-RESULTATE (EPS/Revenue + Surprise) ====
      - name: Pull earnings RESULTS (EPS/Revenue)
        env:
          FINNHUB_TOKEN:   ${{ secrets.FINNHUB_TOKEN || secrets.FINNHUB_API_KEY }}
          FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
          FINNHUB_SLEEP_MS: "1300"
        run: |
          WL="${{ steps.prep.outputs.watchlist }}"
          mkdir -p data/earnings/results
          echo "Earnings-Resultate für Watchlist: $WL"
          python scripts/fetch_earnings_results.py --watchlist "$WL" --outdir data/earnings/results --limit 8
          echo "== Summary (earnings_results.csv) =="
          test -f data/processed/earnings_results.csv && head -n 20 data/processed/earnings_results.csv || true

      # === ETFs (Basics) ===
      - name: Pull ETF basics (Finnhub)
        env:
          FINNHUB_TOKEN:   ${{ secrets.FINNHUB_TOKEN || secrets.FINNHUB_API_KEY }}
          FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
        run: |
          python scripts/fetch_etf_basics.py --watchlist watchlists/etf_sample.txt --out data/processed/etf_basics.csv
          head -n 20 data/processed/etf_basics.csv || true

      # === FX Quotes ===
      - name: Pull FX quotes (Finnhub)
        env:
          FINNHUB_TOKEN:   ${{ secrets.FINNHUB_TOKEN || secrets.FINNHUB_API_KEY }}
          FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
        run: |
          python scripts/fetch_fx_quotes.py --watchlist watchlists/fx_sample.txt --out data/processed/fx_quotes.csv
          head -n 20 data/processed/fx_quotes.csv || true

      # ==== Fundamentals (profile2 + metrics) ====
      - name: Pull FUNDAMENTALS (profile2 + metrics)
        env:
          FINNHUB_TOKEN:   ${{ secrets.FINNHUB_TOKEN || secrets.FINNHUB_API_KEY }}
          FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
          FINNHUB_SLEEP_MS: "1300"
        run: |
          WL="${{ steps.prep.outputs.watchlist }}"
          mkdir -p data/fundamentals
          echo "Fundamentals für Watchlist: $WL"
          python scripts/fetch_fundamentals.py --watchlist "$WL" --outdir data/fundamentals
          echo "== Summary (fundamentals_core.csv) =="
          head -n 20 data/processed/fundamentals_core.csv || true

      # ---- Makro (FRED)
      - name: Pull macro (FRED)
        env:
          FRED_API_KEY: ${{ secrets.FRED_API_KEY }}
        run: |
          mkdir -p data/macro/fred
          python scripts/fetch_fred.py --out data/macro/fred

      # ---- Übersicht
      - name: List written files (sizes)
        run: |
          echo "== data tree =="; find data -type f -printf "%p\t%k KB\n" | sort || true
          echo "== docs tree =="; find docs -type f -printf "%p\t%k KB\n" | sort || true
          test -f data/reports/last_run.json && echo "== last_run.json ==" && cat data/reports/last_run.json || true

      # ---- Fail, wenn nichts produziert wurde
      - name: Fail if outputs empty
        run: |
          cnt=$(find data -type f -size +0c | wc -l || true)
          dcnt=$(find docs -type f -size +0c | wc -l || true)
          echo "Non-empty files in data: $cnt ; in docs: $dcnt"
          if [ "$cnt" -eq 0 ] && [ "$dcnt" -eq 0 ]; then
            echo "No non-empty files produced."
            exit 1
          fi

      # ---- Committen
      - name: Commit updated cache & reports
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add data/ docs/ || true
          git commit -m "Nightly cache update (no LLM)" || echo "Nothing to commit"
          git push

      # ---- Artefakt
      - name: Upload data artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: data-bundle
          path: |
            data/**
            docs/**

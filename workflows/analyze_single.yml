# .github/workflows/analyze_single.yml
name: Analyze equities (Template, single or watchlist)

on:
  workflow_dispatch:
    inputs:
      symbol:
        description: "Optional: einzelnes Symbol (z.B. AAPL). Leer = Watchlist benutzen."
        type: string
        required: false
      limit:
        description: "Optional: nur die ersten N Symbole verarbeiten (zum Testen)"
        type: number
        required: false

permissions:
  contents: write

jobs:
  analyze:
    runs-on: ubuntu-latest

    env:
      WATCHLIST: watchlists/mylist.txt
      OUTDIR:    data/processed/eq_template
      SITE_OUT:  site/eq
      PUBLIC_BASE: ${{ vars.CF_R2_PUBLIC_BASE }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt || true
          pip install pandas yfinance requests python-dateutil
          # Gemini (Google AI API)
          pip install google-genai

      - name: Ensure folders
        run: |
          mkdir -p "$OUTDIR" "$SITE_OUT" site scripts/ai

      - name: Build symbol list (SYMLIST)
        id: syms
        shell: bash
        run: |
          set -e
          SYMLIST=/tmp/symlist.txt
          : > "$SYMLIST"

          if [ -n "${{ github.event.inputs.symbol }}" ]; then
            echo "${{ github.event.inputs.symbol }}" | tr -d '\r' >> "$SYMLIST"
          else
            if [ -f "$WATCHLIST" ]; then
              tail -n +2 "$WATCHLIST" | cut -d',' -f1 | tr -d '\r' | awk 'NF>0' >> "$SYMLIST"
            else
              echo "Watchlist nicht gefunden: $WATCHLIST" >&2
              exit 1
            fi
          fi

          if [ -n "${{ github.event.inputs.limit }}" ] && [ "${{ github.event.inputs.limit }}" -gt 0 ]; then
            head -n "${{ github.event.inputs.limit }}" "$SYMLIST" > /tmp/symlist_limited.txt
            mv /tmp/symlist_limited.txt "$SYMLIST"
          fi

          echo "SYMLIST=$SYMLIST" >> "$GITHUB_ENV"
          echo "count=$(wc -l < "$SYMLIST" | tr -d ' ')" >> "$GITHUB_OUTPUT"

      - name: Render templates (JSON + HTML) for each symbol
        env:
          FINNHUB_TOKEN:   ${{ secrets.FINNHUB_TOKEN }}
          FINNHUB_API_KEY: ${{ secrets.FINNHUB_API_KEY }}
          SEC_USER_AGENT:  ${{ secrets.SEC_USER_AGENT }}
        shell: bash
        run: |
          set -e
          n=0
          while IFS= read -r SYM; do
            [ -z "$SYM" ] && continue
            SYM=$(echo "$SYM" | tr -d '\r')
            echo "== Build $SYM =="
            python scripts/analyze_equity_template.py \
              --symbol "$SYM" \
              --out-json "$OUTDIR/${SYM}.json" \
              --out-html "$SITE_OUT/${SYM}.html" \
              --public-base "${PUBLIC_BASE:-https://pub-CHANGE-ME.r2.dev}" || true
            gzip -f -9 "$OUTDIR/${SYM}.json" || true
            n=$((n+1))
          done < "$SYMLIST"
          echo "Gerenderte Symbole: $n"

      - name: Build JSON index (eq_index.json)
        shell: bash
        run: |
          set -e
          INDEX_JSON=site/eq_index.json
          python - "$INDEX_JSON" "$SYMLIST" << 'PY'
          import sys, json, pathlib
          out, lst = sys.argv[1], sys.argv[2]
          syms = [s.strip() for s in open(lst, 'r', encoding='utf-8').read().splitlines() if s.strip()]
          data = [{"symbol": s, "json": f"data/processed/eq_template/{s}.json.gz", "html": f"site/eq/{s}.html"} for s in syms]
          pathlib.Path(out).write_text(json.dumps(sorted(data, key=lambda x: x["symbol"]), indent=2), encoding="utf-8")
          PY

      - name: Build index.html
        shell: bash
        run: |
          set -e
          cat > site/index.html <<'HTML'
          <!doctype html>
          <meta charset="utf-8">
          <title>Equity Templates</title>
          <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
          <style>
          body{font:14px/1.5 system-ui,Segoe UI,Roboto,Arial;padding:24px;background:#0f1116;color:#e6e6e6}
          a{color:#7bd4ff;text-decoration:none}a:hover{text-decoration:underline}
          .card{max-width:900px;margin:0 auto}
          h1{margin:0 0 8px 0}.muted{color:#9aa4ad}
          ul{columns:3;gap:24px}li{margin:6px 0}
          </style>
          <div class="card">
            <h1>Equity Templates</h1>
            <div class="muted">Ticker aus der Watchlist</div>
            <ul>
          HTML
          awk '{print "  <li><a href=\"eq/"$0".html\">" $0 "</a></li>"}' "$SYMLIST" >> site/index.html
          echo "  </ul>"   >> site/index.html
          echo "</div>"    >> site/index.html

      # ---------- Gemini: kleines Analyse-Skript einchecken, falls nicht vorhanden ----------
      - name: Write Gemini analyzer (if missing)
        shell: bash
        run: |
          set -e
          if [ ! -f scripts/ai/analyze_with_gemini.py ]; then
            cat > scripts/ai/analyze_with_gemini.py << 'PY'
          #!/usr/bin/env python3
          # -*- coding: utf-8 -*-
          import os, sys, json, gzip, time, pathlib
          from typing import Dict, Any
          from google import genai

          def load_json_any(path:str)->Dict[str,Any]:
            p = pathlib.Path(path)
            if p.suffix == ".gz":
              with gzip.open(p, "rt", encoding="utf-8") as f: return json.load(f)
            return json.load(open(p, "r", encoding="utf-8"))

          def main():
            import argparse
            ap = argparse.ArgumentParser()
            ap.add_argument("--watchlist", required=True)
            ap.add_argument("--eqdir", default="data/processed/eq_template")
            ap.add_argument("--out", default="data/processed/ai_analysis.jsonl")
            ap.add_argument("--limit", type=int, default=0)
            ap.add_argument("--model", default="gemini-2.5-pro")
            args = ap.parse_args()

            api_key = os.getenv("GOOGLE_API_KEY","")
            if not api_key:
              print("NO GOOGLE_API_KEY provided; skipping.", file=sys.stderr)
              open(args.out, "w").close()
              return

            client = genai.Client(api_key=api_key)

            syms = [s.strip() for s in open(args.watchlist,encoding="utf-8").read().splitlines() if s.strip()]
            if args.limit and args.limit>0: syms = syms[:args.limit]

            out = open(args.out, "w", encoding="utf-8")
            for i, sym in enumerate(syms, 1):
              jpath_gz = f"{args.eqdir}/{sym}.json.gz"
              jpath = f"{args.eqdir}/{sym}.json"
              src = jpath_gz if os.path.exists(jpath_gz) else jpath
              if not os.path.exists(src):
                print(f"[skip] no template for {sym}", file=sys.stderr); continue

              try:
                data = load_json_any(src)
                brief = {
                  "symbol": sym,
                  "name": data.get("profile",{}).get("name") or data.get("symbol", sym),
                  "sector": data.get("profile",{}).get("sector"),
                  "market": data.get("profile",{}).get("exchange"),
                  "key": {
                    "cds_proxy": data.get("credit",{}).get("cds_proxy"),
                    "next_earnings": data.get("earnings",{}).get("next"),
                    "options_bias": data.get("options",{}).get("bias"),
                  }
                }
                prompt = (
                  "You are an equity analyst. In ~6 bullet points, summarize opportunities and risks.\n"
                  "Input is a compact JSON excerpt from my dataset (credit proxy, options bias, next earnings).\n"
                  "Return JSON with keys: summary (markdown), stance (one of: Bullish, Neutral, Bearish), "
                  "confidence (0..100).\n"
                  f"INPUT:\n{json.dumps(brief, ensure_ascii=False)}"
                )
                resp = client.models.generate_content(
                  model=args.model,
                  contents=prompt,
                )
                txt = (resp.text or "").strip()
                try:
                  # try to parse JSON from model; otherwise wrap as summary
                  parsed = json.loads(txt)
                except Exception:
                  parsed = {"summary": txt, "stance": "Neutral", "confidence": 50}

                row = {
                  "ts": int(time.time()),
                  "symbol": sym,
                  "input_path": src,
                  "model": args.model,
                  "result": parsed
                }
                out.write(json.dumps(row, ensure_ascii=False) + "\n")
                out.flush()
                time.sleep(0.2)  # kleine Pause gegen 429
              except Exception as e:
                row = {"ts": int(time.time()), "symbol": sym, "error": str(e)}
                out.write(json.dumps(row, ensure_ascii=False) + "\n")
            out.close()

          if __name__ == "__main__":
            main()
          PY
            chmod +x scripts/ai/analyze_with_gemini.py
          fi

      - name: Gemini AI analysis (JSONL)
        env:
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
        shell: bash
        run: |
          set -e
          python scripts/ai/analyze_with_gemini.py \
            --watchlist "$SYMLIST" \
            --eqdir "data/processed/eq_template" \
            --out "data/processed/ai_analysis.jsonl" \
            --limit "${{ github.event.inputs.limit || 0 }}"
          gzip -f -9 data/processed/ai_analysis.jsonl || true
          echo "AI analysis ready → data/processed/ai_analysis.jsonl.gz"

      - name: Upload to R2 (analysis-pro bucket)
        env:
          CF_R2_ACCESS_KEY_ID:     ${{ secrets.CF_R2_ACCESS_KEY_ID }}
          CF_R2_SECRET_ACCESS_KEY: ${{ secrets.CF_R2_SECRET_ACCESS_KEY }}
          CF_R2_BUCKET:            ${{ secrets.CF_R2_BUCKET }}
          CF_R2_ENDPOINT:          ${{ secrets.CF_R2_ENDPOINT }}
        shell: bash
        run: |
          set -e
          # Secrets prüfen – sonst sauber skippen
          if [ -z "${CF_R2_BUCKET}" ] || [ -z "${CF_R2_ENDPOINT}" ] || \
             [ -z "${CF_R2_ACCESS_KEY_ID}" ] || [ -z "${CF_R2_SECRET_ACCESS_KEY}" ]; then
            echo "R2 nicht konfiguriert – Upload wird übersprungen."
            exit 0
          fi

          curl -fsSL https://rclone.org/install.sh | sudo bash
          cat > rclone.conf <<EOF
          [r2]
          type = s3
          provider = Cloudflare
          access_key_id = ${CF_R2_ACCESS_KEY_ID}
          secret_access_key = ${CF_R2_SECRET_ACCESS_KEY}
          endpoint = ${CF_R2_ENDPOINT}
          force_path_style = true
          no_check_bucket = true
          EOF
          rclone copy "data/processed/eq_template" "r2:${CF_R2_BUCKET}/data/processed/eq_template" --config rclone.conf --s3-no-check-bucket -v
          rclone copy "site/eq"                     "r2:${CF_R2_BUCKET}/site/eq"                      --config rclone.conf --s3-no-check-bucket -v
          rclone copy "site/index.html"             "r2:${CF_R2_BUCKET}/site"                         --config rclone.conf --s3-no-check-bucket -v
          rclone copy "site/eq_index.json"          "r2:${CF_R2_BUCKET}/site"                         --config rclone.conf --s3-no-check-bucket -v
          # AI Output zusätzlich hochladen
          if [ -f "data/processed/ai_analysis.jsonl.gz" ]; then
            rclone copy "data/processed/ai_analysis.jsonl.gz" "r2:${CF_R2_BUCKET}/data/processed" --config rclone.conf --s3-no-check-bucket -v
          fi

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: eq-template-site
          path: |
            site/**
            data/processed/eq_template/**
            data/processed/ai_analysis.jsonl.gz
